{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import reshape,transpose,squeeze,GradientTape,expand_dims\n",
    "from tensorflow.keras.layers import Dense,Input,GRU,Conv1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import losses,optimizers\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from spektral.layers import GCNConv,GATConv\n",
    "from spektral.utils.convolution import gcn_filter"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Model**: STGCN may be a possible method to handle with spatial-temporal prediction. Why such structure is needed?\n",
    "    - [pytorch implementation](https://github.com/LMissher/STGNN)\n",
    "    - [original](https://github.com/VeritasYin/STGCN_IJCAI-18)\n",
    "- **Predict**: *T*-times 1-step prediction OR T-step prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimate:\n",
    "    def __init__(self,conv=None,edges=None,resnet=False,recurrent=None,args=None):\n",
    "        self.n_node = getattr(args,'n_node',5)\n",
    "        self.n_in = getattr(args,'n_in',5)\n",
    "        self.n_out = getattr(args,'n_out',3)\n",
    "        self.seq_len = getattr(args,'seq_len',6)\n",
    "        self.embed_size = getattr(args,'embed_size',64)\n",
    "        self.hidden_dim = getattr(args,\"hidden_dim\",64)\n",
    "        self.n_layer = getattr(args,\"n_layer\",3)\n",
    "\n",
    "        self.hmax = getattr(args,\"hmax\",np.array([1.5 for _ in range(self.n_node)]))\n",
    "        if edges is not None:\n",
    "            self.edges = edges\n",
    "            self.filter = self.get_adj(edges)\n",
    "        self.conv = conv\n",
    "        self.recurrent = recurrent\n",
    "        self.model = self.build_network(conv,resnet,recurrent)\n",
    "        self.loss_fn = losses.get(getattr(args,\"loss_function\",\"MeanSquaredError\"))\n",
    "        self.optimizer = optimizers.get(getattr(args,\"optimizer\",\"Adam\"))\n",
    "        self.optimizer.learning_rate = getattr(args,\"learning_rate\",1e-3)\n",
    "\n",
    "    def get_adj(self,edges):\n",
    "        A = np.zeros((edges.max()+1,edges.max()+1)) # adjacency matrix\n",
    "        for u,v in edges:\n",
    "            A[u,v] += 1\n",
    "        return A\n",
    "\n",
    "    def build_network(self,conv=None,resnet=False,recurrent=None):\n",
    "        # (T,N,in) (T,in*N) (N,in) (in*N)\n",
    "        input_shape = (self.n_node,self.n_in) if conv else (self.n_node * self.n_in,)\n",
    "        if recurrent:\n",
    "            input_shape = (self.seq_len,) + input_shape\n",
    "        X_in = Input(shape=input_shape)\n",
    "        x = X_in.copy()\n",
    "        \n",
    "        if conv:\n",
    "            A_in = Input(self.filter.shape[0],)\n",
    "            inp = [X_in,A_in]\n",
    "            if 'GCN' in conv:\n",
    "                self.filter,net = gcn_filter(self.filter),GCNConv\n",
    "            elif 'GAT' in conv:\n",
    "                net = GATConv\n",
    "            elif 'CNN' in conv:\n",
    "                # TODO: CNN\n",
    "                net \n",
    "            else:\n",
    "                raise AssertionError(\"Unknown Convolution layer %s\"%str(conv))\n",
    "        else:\n",
    "            inp,net = X_in,Dense\n",
    "        \n",
    "        # (B,T,N,in) (B,T,in*N) --> (B*T,N,in) (B*T,in*N)\n",
    "        x = reshape(x,(-1,)+input_shape[1:]) if recurrent else x\n",
    "        for _ in range(self.n_layer):\n",
    "            x = [x,A_in] if conv else x\n",
    "            x_out = net(self.embed_size,activation='relu')(x)\n",
    "            x = x_out + x if resnet else x_out\n",
    "\n",
    "        if recurrent:\n",
    "            # (B*T,N,E) (B*T,E) --> (B,T,N,E) (B,T,E)\n",
    "            x = reshape(x,(-1,)+input_shape[:-1]+(self.embed_size,))\n",
    "            # (B,T,N,E) (B,T,E) --> (B,N,T,E) (B,T,E)\n",
    "            x = transpose(x,[0,2,1,3]) if conv else x\n",
    "            \n",
    "            if recurrent == 'Conv1D':\n",
    "                # (B,N,T,E) (B,T,E) --> (B,N,H) (B,H)\n",
    "                x = Conv1D(self.hidden_dim,self.seq_len,activation='relu',input_shape=x.shape[-2:])(x)\n",
    "                x = squeeze(x)\n",
    "            elif recurrent == 'GRU':\n",
    "                # (B,N,T,E) (B,T,E) --> (B*N,T,E) (B,T,E)\n",
    "                x = reshape(x,(-1,self.seq_len,self.embed_size)) if conv else x\n",
    "                x = GRU(self.hidden_dim)(x)\n",
    "                # (B*N,H) (B,H) --> (B,N,H) (B,H)\n",
    "                x = reshape(x,(-1,self.n_node,self.hidden_dim)) if conv else x\n",
    "            else:\n",
    "                raise AssertionError(\"Unknown recurrent layer %s\"%str(recurrent))\n",
    "\n",
    "        out_shape = self.n_out if conv else self.n_out * self.n_node\n",
    "        out = Dense(out_shape,activation='linear')(x)\n",
    "        model = Model(inputs=inp, outputs=out)\n",
    "        return model\n",
    "    \n",
    "    def train(self,x,y):\n",
    "        with GradientTape() as tape:\n",
    "            tape.watch(self.model.trainable_variables)\n",
    "            pred = self.model(x)\n",
    "            loss = self.loss_fn(y,pred)\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads,self.model.trainable_variables))\n",
    "        return loss.numpy()\n",
    "    \n",
    "    def predict(self,x):\n",
    "        x = expand_dims(x,0)\n",
    "        return squeeze(self.model(x),0).numpy()\n",
    "\n",
    "    def constrain(self,y,r):\n",
    "        # y,r are 2-d\n",
    "        # r should be at the same step with q_ds\n",
    "        if self.conv:\n",
    "            h,q_us,q_ds = [y[:,:,i] for i in range(3)]\n",
    "        else:\n",
    "            h,q_us,q_ds = y[:,:self.n_node],y[:,self.n_node:self.n_node*2],y[:,self.n_node*2:]\n",
    "        # q_us = [np.zeros((y.shape[0],)) for _ in self.n_node]\n",
    "        # for u,v in self.edges:\n",
    "        #     q_us[v] += q_ds[u]\n",
    "        # q_us = np.array(q_us).T\n",
    "        q_w = (q_us + r - q_ds).clip(0) * (h > self.hmax)\n",
    "        return (h,q_us,q_ds,q_w)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self,env,seq_len = 4,act = False):\n",
    "        self.env = env\n",
    "        self.seq_len = seq_len\n",
    "        if act:\n",
    "            self.action_table = list(env.config['action_space'].values())\n",
    "    \n",
    "    def simulate(self, event, act = False):\n",
    "        state = self.env.reset(event,global_state=True,seq=self.seq_len)\n",
    "        states,settings = [state],[]\n",
    "        done = False\n",
    "        while not done:\n",
    "            setting = [table[np.random.randint(0,len(table))] for table in self.action_table] if act else None\n",
    "            done = self.env.step(setting)\n",
    "            state = self.env.state(seq=self.seq_len)\n",
    "            states.append(state)\n",
    "            settings.append(setting)\n",
    "        return np.array(states),np.array(settings) if act else None\n",
    "    \n",
    "    def state_split(self,states,settings=None):\n",
    "        if settings is not None:\n",
    "            # B,T,N,S\n",
    "            states = states[:settings.shape[0]+1,:,:,:]\n",
    "            # B,T,n_act\n",
    "            a = np.tile(np.expand_dims(settings,axis=1),[1,self.seq_len,1])\n",
    "        h,q_totin,q_ds,r = [states[:,:,:,i] for i in range(4)]\n",
    "        q_us = q_totin - r\n",
    "        # B,T,N,in\n",
    "        X = np.stack([h[:-1],q_us[:-1],q_ds[:-1],r[1:]],axis=-1)\n",
    "        Y = np.stack([h[1:,-1,:],q_us[1:,-1,:],q_ds[1:,-1,:]],axis=-1)\n",
    "        if settings is not None:\n",
    "            X = np.concatenate([X,a],axis=-1)\n",
    "        return X,Y\n",
    "\n",
    "    def generate(self,events,processes=5,act=False):\n",
    "        pool = mp.Pool(processes)\n",
    "        if processes > 1:\n",
    "            res = [pool.apply_async(func=self.simulate,args=(event,act,)) for event in events]\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            res = [self.state_split(*r.get()) for r in res]\n",
    "        else:\n",
    "            res = [self.state_split(*self.simulate(event,act)) for event in events]\n",
    "        self.X,self.Y = [np.concatenate([r[i] for r in res],axis=0) for i in range(2)]\n",
    "        self.length = self.X.shape[0]\n",
    "    \n",
    "    def sample(self,size):\n",
    "        idx = np.random.choice(range(self.length),size)\n",
    "        return self.X[idx],self.Y[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chong\\anaconda3\\envs\\storm\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from swmm_api import read_inp_file\n",
    "from envs import shunqing\n",
    "env = shunqing()\n",
    "inp = read_inp_file(env.config['swmm_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in inp.TIMESERIES.items():\n",
    "    if k.startswith(env.config['rainfall']['suffix']):\n",
    "        dura = v.data[-1][0] - v.data[0][0]\n",
    "        st = (inp.OPTIONS['START_DATE'],inp.OPTIONS['START_TIME'])\n",
    "        st = datetime(st[0].year,st[0].month,st[0].day,st[1].hour,st[1].minute,st[1].second)\n",
    "        et = (st + dura)\n",
    "        inp.OPTIONS['END_DATE'],inp.OPTIONS['END_TIME'] = et.date(),et.time()\n",
    "        inp.RAINGAGES['RainGage'].Timeseries = k\n",
    "        inp.write_file(env.config['rainfall']['filedir']+k+'.inp')\n",
    "events = [env.config['rainfall']['filedir']+k+'.inp' for k in inp.TIMESERIES if k.startswith(env.config['rainfall']['suffix'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dG = DataGenerator(env,seq_len=4)\n",
    "dG.generate(events,processes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20396, 113, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dG.Y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "storm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
